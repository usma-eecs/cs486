{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS486 - Artificial Intelligence\n",
    "## Lesson 22 - Markov Chains\n",
    "\n",
    "Today we will discuss how to build Markov Chains that approximate the probability distribution over a set of random variables. Markov chains are the simplest form of Markov models are useful for predictive modeling. \n",
    "\n",
    "Here's an example of using Markov chains to generate English sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i were the maddest of the sides a square there ...\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "from aima.text import *\n",
    "from utils import open_data\n",
    "\n",
    "text = open_data(\"EN-text/flatland.txt\").read()\n",
    "model = NgramWordModel(3, words(text))\n",
    "print(model.samples(10), \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains are how your phone suggests the next word in a sentence you're typing and spell checkers find the closest word to a misspelled word.\n",
    "\n",
    "So how does it work? We'll need a few more probability tricks to understand.  \n",
    "\n",
    "### Bayes' Rule\n",
    "\n",
    "Bayes' rule is considered to be the most important equation in AI:  \n",
    "\n",
    "> The essence of the Bayesian approach is to provide a mathematical rule explaining how you should change your existing beliefs in the light of new evidence. In other words, it allows scientists to combine new data with their existing knowledge or expertise. \n",
    "*<p>[In Praise of Bayes](https://www.economist.com/science-and-technology/2000/09/28/in-praise-of-bayes)</p>*\n",
    "\n",
    "Suppose you have two coins: A fair coins and a coin with heads on both sides. If you pulled one of the two coins from a bag at random, the probability of pulling the fair coin would be 1 in 2. Now suppose someone else pulls a coin and flips head. What are the odds, given this observation, that they pulled the fair coin ($x$)? We can use Bayes' Rule, on the left below, to compute it:\n",
    "\n",
    "$$P(x|y) = \\frac{P(y|x)}{P(y)}P(x) = \\frac{\\frac{1}{2}}{\\frac{3}{4}}\\frac{1}{2} = \\frac{1}{3}$$\n",
    "\n",
    "Here's a short video that provides an intuition for Bayes' Rule using the coin example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/Zxm4Xxvzohk?rel=0&showinfo=0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x11935e9b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('Zxm4Xxvzohk?rel=0&showinfo=0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' Rule can also be though of as:\n",
    "\n",
    "```\n",
    "                 likelihood * prior\n",
    "    posterior = ----------------------\n",
    "                 marginal likelihood\n",
    "```                  \n",
    "\n",
    "The denominator is just a normalizing constant that ensures the posterior adds up to 1; it can be computed by summing up the numerator over all possible values the conditional can take on. If you don't normalize, you can write Bayes' rule as:\n",
    "\n",
    "$$ P(x\\mid{y}) \\propto P(y\\mid{x})P(x) $$\n",
    "\n",
    "## Independence\n",
    "\n",
    "Two variables are independent if they have no effect on each other. Consider the probability distribution of a coin:\n",
    "\n",
    "| Coin   |  P  |\n",
    "|--------|-----|\n",
    "| heads  | 0.5 | \n",
    "| tails  | 0.5 | \n",
    "\n",
    "Now consider the distribution of two coin flips:\n",
    "\n",
    "| Coin1 | Coin2 | P |\n",
    "|-------|-------|---|\n",
    "| heads  | heads  | 0.25 | \n",
    "| heads  | tails  | 0.25 | \n",
    "| tails  | heads  | 0.25 | \n",
    "| tails  | tails  | 0.25 | \n",
    "\n",
    "The distribution is simply the product of each individual distribution, which is the definition of **independence**:\n",
    "\n",
    "$$ X{\\perp\\!\\!\\!\\perp}Y \\iff P(X,Y) = P(X)P(Y) = \\forall x,y P(x,y) = P(x)P(y) $$\n",
    "\n",
    "In practice, variables are seldom independent, but it is *modeling assumption* that can greatly simplify our model. \n",
    "\n",
    "## Conditional Independence \n",
    "\n",
    "**Conditional independence** is our most basic and robust form of knowledge about uncertain environments. A variable is be conditionally independent of another if, presented some evidence, the likelihood of one is not influenced by the other. For example, height and vocabulary are dependent but they are conditionally independent given age. We would write that as:\n",
    "\n",
    "$$ P(Vocabulary \\mid{Height,Age}) = P(Vocabulary \\mid{Age}) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Models\n",
    "\n",
    "We want to model a joint distribution without computing the full join. Suppose $X$ is a **state** at a given time. Each state encodes the joint distribution over all of our variables. We connect states linearly and assume that states that are not connected are independent. \n",
    "\n",
    "![Markov Chain](images/markov_chain.png \"Markov Chain\")\n",
    "\n",
    "We would write the independence as:\n",
    "\n",
    "$$ X_t {\\perp\\!\\!\\!\\perp} X_1,..,X_{t-2}\\mid{X_{t-1}} $$\n",
    "\n",
    "The independence assumption is a strong and probably doesn't hold in reality, but we're only looking for an approximation. Another assumption is that our transition model is stationary. In other words, $P(X_t\\mid{X_{t-1}})$ doesn't change with $t$. \n",
    "\n",
    "So what does a transition model look like? Consider the partial transition model for a sentence generator that trained on *I am Sam. Sam I am. I do not like green eggs and ham.*\n",
    "\n",
    "![Unigrams](images/unigrams.png \"Unigrams\")\n",
    "\n",
    "## Mini-Forward Algorithm\n",
    "\n",
    "Some Markov Chains have a **stationary distribution**,$P(X_{\\infty})$. Intuitively, the stationary distribution tells us the probability, if we moved an infinite number of times through our transition model, of a value being assigned. Given an initial observation, we can compute the stationary distribution using the **Mini-Forward Algorithm**:\n",
    "\n",
    "$$ P(x_1) = prior\\ observation$$\n",
    "$$ P(x_t) = \\sum_{x_{t-1}}P(x_t\\mid{x_{t-1}})P(x_{t-1})$$\n",
    "\n",
    "This is essentially the Bellman equation of probability distributions. It gives us a way to iterate our values until they converge. \n",
    "\n",
    "Stationary distributions are useful. PageRank, for example, is a stationary distribution of a Markov chain. Not all Markov chains have a stationary distribution. Our sentence generator, for example, does not. Why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
